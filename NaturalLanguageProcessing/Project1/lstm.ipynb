{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM-Model for Text Generation\n",
    "\n",
    "Some reference on LSTMs:\n",
    "* Colah, <https://colah.github.io/posts/2015-08-Understanding-LSTMs/>\n",
    "* Pytorch tutorial, <https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html>\n",
    "* Text Generation With Pytorch, <https://machinetalk.org/2019/02/08/text-generation-with-pytorch/>\n",
    "* Language Modelling and Text Generation using LSTMs — Deep Learning for NLP, <https://medium.com/@shivambansal36/language-modelling-text-generation-using-lstms-deep-learning-for-nlp-ed36b224b275>\n",
    "\n",
    "![Text generation](https://machinetalk.org/wp-content/uploads/2019/02/predict.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from collections import Counter\n",
    "from argparse import Namespace\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(level = logging.INFO)\n",
    "handler = logging.FileHandler(\"lstm-5.log\")\n",
    "handler.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "flags = Namespace(\n",
    "    train_file_path='dict_no_stop_jieba',\n",
    "    checkpoint_path='checkpoint',\n",
    "    seq_size=32,\n",
    "    batch_size=64,\n",
    "    embedding_size=128,\n",
    "    lstm_size=128,\n",
    "    gradients_norm=5,\n",
    "    top_k=5,\n",
    "    num_epochs=40,\n",
    "    learning_rate=0.001\n",
    ")\n",
    "\n",
    "logger.info(str(flags))\n",
    "if not os.path.exists(flags.checkpoint_path):\n",
    "    os.mkdir(flags.checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "class TextDataset(data.Dataset):\n",
    "    \"\"\"\n",
    "    My own text dataset\n",
    "    ref: https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel\n",
    "    \"\"\"\n",
    "    def __init__(self, file_path, batch_size, seq_size):\n",
    "        \"\"\"\n",
    "        Generate word indices and dictionary used for training\n",
    "\n",
    "        file_path: The path of the folder storing all the news\n",
    "        batch_size: size of one batch (used for batch training)\n",
    "        seq_size: size of the sequence\n",
    "        \"\"\"\n",
    "        text = []\n",
    "        for i,file_name in enumerate(os.listdir(file_path),1):\n",
    "            with open(\"{}/{}\".format(file_path,file_name),\"r\",encoding=\"utf-8\") as infile:\n",
    "                for j,line in enumerate(infile):\n",
    "                    text += line.split()\n",
    "        word_counts = Counter(text) # {word: count}\n",
    "        # sort based on counts, but only remain the word strings\n",
    "        sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "\n",
    "        # make embedding based on the occurance frequency of the words\n",
    "        self.int_to_word = {k: w for k, w in enumerate(sorted_vocab)}\n",
    "        self.word_to_int = {w: k for k, w in self.int_to_word.items()}\n",
    "        self.n_word = len(self.int_to_word)\n",
    "        print('Vocabulary size', self.n_word)\n",
    "\n",
    "        # turn all the words in the text to int\n",
    "        int_text = [self.word_to_int[w] for w in text]\n",
    "        num_batches = int(len(int_text) / (seq_size * batch_size))\n",
    "        in_text = int_text[:num_batches * batch_size * seq_size]\n",
    "\n",
    "        # shift right for one position to generate the 'label' Y\n",
    "        out_text = np.zeros_like(in_text)\n",
    "        out_text[:-1] = in_text[1:]\n",
    "        out_text[-1] = in_text[0]\n",
    "\n",
    "        # reshape X and Y (# of seq,seq_size)\n",
    "        self.in_text = np.reshape(in_text,(-1,seq_size))\n",
    "        self.out_text = np.reshape(out_text,(-1,seq_size))\n",
    "        self.seq_size = seq_size\n",
    "#     return int_to_word, word_to_int, n_word, in_text, out_text\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the total number of samples\n",
    "        \"\"\"\n",
    "        return len(self.in_text)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Generate one sample of the data\n",
    "        \"\"\"\n",
    "        x = self.in_text[idx]\n",
    "        y = self.out_text[idx]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LSTM Basic Unit](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModule(nn.Module):\n",
    "    \"\"\"\n",
    "    A basic LSTM model for text generation\n",
    "    \"\"\"\n",
    "    def __init__(self, n_word, seq_size, embedding_size, lstm_size):\n",
    "        super(RNNModule, self).__init__()\n",
    "        self.seq_size = seq_size\n",
    "        self.lstm_size = lstm_size\n",
    "        \n",
    "        # embed = nn.Embedding(vocab_size, vector_size)\n",
    "        # `vocab_size` is the number of words in your train, val and test set\n",
    "        # `vector_size` is the dimension of the word vectors you are using\n",
    "        # you can view it as a linear transformation\n",
    "        # the tensor is initialized randomly\n",
    "        self.embedding = nn.Embedding(n_word, embedding_size)\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_size, lstm_size, batch_first=True)\n",
    "        self.linear = nn.Linear(lstm_size, n_word)\n",
    "\n",
    "    def forward(self, x, prev_state):\n",
    "        \"\"\"\n",
    "        Forward propagation\n",
    "        \"\"\"\n",
    "        embedding = self.embedding(x)\n",
    "        # used for next layer\n",
    "        output, state = self.lstm(embedding, prev_state)\n",
    "        # used for output\n",
    "        logits = self.linear(output)\n",
    "        return logits, state\n",
    "\n",
    "    def zero_state(self, batch_size):\n",
    "        \"\"\"\n",
    "        Used to make the state all zeros\n",
    "        \"\"\"\n",
    "        return (torch.zeros(1, batch_size, self.lstm_size),\n",
    "                torch.zeros(1, batch_size, self.lstm_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, sys\n",
    "\n",
    "def train():\n",
    "    \"\"\"\n",
    "    Core training function\n",
    "    \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    train_set = TextDataset(flags.train_file_path, flags.batch_size, flags.seq_size)\n",
    "    train_loader = data.DataLoader(dataset=train_set,batch_size=flags.batch_size,shuffle=False)\n",
    "\n",
    "    net = RNNModule(train_set.n_word, flags.seq_size, flags.embedding_size, flags.lstm_size)\n",
    "    net = net.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=flags.learning_rate)\n",
    "\n",
    "    iteration = 0\n",
    "    losses = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    for e in range(flags.num_epochs):\n",
    "        state_h, state_c = net.zero_state(flags.batch_size)\n",
    "        state_h = state_h.to(device)\n",
    "        state_c = state_c.to(device)\n",
    "        \n",
    "        for step, (x, y) in enumerate(train_loader):\n",
    "            iteration += 1\n",
    "            net.train()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x = torch.tensor(x).to(device)\n",
    "            y = torch.tensor(y).to(device)\n",
    "\n",
    "            logits, (state_h, state_c) = net(x, (state_h, state_c))\n",
    "            loss = criterion(logits.transpose(1, 2), y)\n",
    "\n",
    "            loss_value = loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # avoid delivering loss from h_t and c_t\n",
    "            # thus need to remove them from the computation graph\n",
    "            state_h = state_h.detach()\n",
    "            state_c = state_c.detach()\n",
    "\n",
    "            # avoid gradient explosion\n",
    "            _ = torch.nn.utils.clip_grad_norm_(net.parameters(), flags.gradients_norm)\n",
    "\n",
    "            optimizer.step()\n",
    "            losses.append(loss_value)\n",
    "\n",
    "            if iteration % 100 == 0:\n",
    "                print('Epoch: {}/{}'.format(e+1, flags.num_epochs),\n",
    "                      'Iteration: {}'.format(iteration),\n",
    "                      'Loss: {}'.format(loss_value))\n",
    "                logger.info('Epoch: {}/{} Iteration: {} Loss: {}'.format(e+1, flags.num_epochs, iteration, loss_value))\n",
    "\n",
    "            if iteration % 1000 == 0:\n",
    "                torch.save(net.state_dict(),\n",
    "                           '{}/model-{}.pth'.format(flags.checkpoint_path,iteration))\n",
    "\n",
    "    print(\"Time:{}s\".format(time.time()-start_time))\n",
    "    torch.save(net.state_dict(),'{}/model-{}.pth'.format(flags.checkpoint_path,\"final\"))\n",
    "    return net, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size 48469\n",
      "Epoch: 1/40 Iteration: 100 Loss: 7.927405834197998\n",
      "Epoch: 1/40 Iteration: 200 Loss: 7.559329509735107\n",
      "Epoch: 1/40 Iteration: 300 Loss: 7.860358238220215\n",
      "Epoch: 1/40 Iteration: 400 Loss: 7.498166084289551\n",
      "Epoch: 2/40 Iteration: 500 Loss: 7.301557540893555\n",
      "Epoch: 2/40 Iteration: 600 Loss: 7.3907151222229\n",
      "Epoch: 2/40 Iteration: 700 Loss: 7.1585564613342285\n",
      "Epoch: 2/40 Iteration: 800 Loss: 7.161759853363037\n",
      "Epoch: 3/40 Iteration: 900 Loss: 6.438643932342529\n",
      "Epoch: 3/40 Iteration: 1000 Loss: 6.713354587554932\n",
      "Epoch: 3/40 Iteration: 1100 Loss: 6.914454936981201\n",
      "Epoch: 3/40 Iteration: 1200 Loss: 7.107439994812012\n",
      "Epoch: 3/40 Iteration: 1300 Loss: 6.821282386779785\n",
      "Epoch: 4/40 Iteration: 1400 Loss: 6.807150840759277\n",
      "Epoch: 4/40 Iteration: 1500 Loss: 7.3239288330078125\n",
      "Epoch: 4/40 Iteration: 1600 Loss: 7.0144829750061035\n",
      "Epoch: 4/40 Iteration: 1700 Loss: 6.422833442687988\n",
      "Epoch: 5/40 Iteration: 1800 Loss: 5.858368396759033\n",
      "Epoch: 5/40 Iteration: 1900 Loss: 6.2130303382873535\n",
      "Epoch: 5/40 Iteration: 2000 Loss: 6.151628494262695\n",
      "Epoch: 5/40 Iteration: 2100 Loss: 6.397706031799316\n",
      "Epoch: 6/40 Iteration: 2200 Loss: 6.39582633972168\n",
      "Epoch: 6/40 Iteration: 2300 Loss: 6.009792804718018\n",
      "Epoch: 6/40 Iteration: 2400 Loss: 5.779262065887451\n",
      "Epoch: 6/40 Iteration: 2500 Loss: 6.113592147827148\n",
      "Epoch: 6/40 Iteration: 2600 Loss: 4.537585735321045\n",
      "Epoch: 7/40 Iteration: 2700 Loss: 5.786798000335693\n",
      "Epoch: 7/40 Iteration: 2800 Loss: 5.021177768707275\n",
      "Epoch: 7/40 Iteration: 2900 Loss: 5.170769214630127\n",
      "Epoch: 7/40 Iteration: 3000 Loss: 5.494401931762695\n",
      "Epoch: 8/40 Iteration: 3100 Loss: 5.26159143447876\n",
      "Epoch: 8/40 Iteration: 3200 Loss: 4.986721992492676\n",
      "Epoch: 8/40 Iteration: 3300 Loss: 5.884077548980713\n",
      "Epoch: 8/40 Iteration: 3400 Loss: 5.604245185852051\n",
      "Epoch: 9/40 Iteration: 3500 Loss: 4.874413967132568\n",
      "Epoch: 9/40 Iteration: 3600 Loss: 5.173380374908447\n",
      "Epoch: 9/40 Iteration: 3700 Loss: 4.420036792755127\n",
      "Epoch: 9/40 Iteration: 3800 Loss: 4.865848541259766\n",
      "Epoch: 9/40 Iteration: 3900 Loss: 5.251748085021973\n",
      "Epoch: 10/40 Iteration: 4000 Loss: 5.55714225769043\n",
      "Epoch: 10/40 Iteration: 4100 Loss: 4.837856769561768\n",
      "Epoch: 10/40 Iteration: 4200 Loss: 4.795151710510254\n",
      "Epoch: 10/40 Iteration: 4300 Loss: 4.233919620513916\n",
      "Epoch: 11/40 Iteration: 4400 Loss: 4.823065280914307\n",
      "Epoch: 11/40 Iteration: 4500 Loss: 4.477650165557861\n",
      "Epoch: 11/40 Iteration: 4600 Loss: 5.287561893463135\n",
      "Epoch: 11/40 Iteration: 4700 Loss: 5.040602684020996\n",
      "Epoch: 12/40 Iteration: 4800 Loss: 4.398131370544434\n",
      "Epoch: 12/40 Iteration: 4900 Loss: 4.681077003479004\n",
      "Epoch: 12/40 Iteration: 5000 Loss: 4.650769233703613\n",
      "Epoch: 12/40 Iteration: 5100 Loss: 4.336888790130615\n",
      "Epoch: 12/40 Iteration: 5200 Loss: 4.765099048614502\n",
      "Epoch: 13/40 Iteration: 5300 Loss: 4.3706207275390625\n",
      "Epoch: 13/40 Iteration: 5400 Loss: 5.138561725616455\n",
      "Epoch: 13/40 Iteration: 5500 Loss: 4.582671642303467\n",
      "Epoch: 13/40 Iteration: 5600 Loss: 4.332777976989746\n",
      "Epoch: 14/40 Iteration: 5700 Loss: 4.4237871170043945\n",
      "Epoch: 14/40 Iteration: 5800 Loss: 3.9725193977355957\n",
      "Epoch: 14/40 Iteration: 5900 Loss: 4.56098747253418\n",
      "Epoch: 14/40 Iteration: 6000 Loss: 4.366333961486816\n",
      "Epoch: 15/40 Iteration: 6100 Loss: 3.8026773929595947\n",
      "Epoch: 15/40 Iteration: 6200 Loss: 4.772393226623535\n",
      "Epoch: 15/40 Iteration: 6300 Loss: 4.331607818603516\n",
      "Epoch: 15/40 Iteration: 6400 Loss: 3.8438656330108643\n",
      "Epoch: 15/40 Iteration: 6500 Loss: 3.9355249404907227\n",
      "Epoch: 16/40 Iteration: 6600 Loss: 4.289780616760254\n",
      "Epoch: 16/40 Iteration: 6700 Loss: 3.5224087238311768\n",
      "Epoch: 16/40 Iteration: 6800 Loss: 4.7452802658081055\n",
      "Epoch: 16/40 Iteration: 6900 Loss: 3.902381658554077\n",
      "Epoch: 17/40 Iteration: 7000 Loss: 4.11329460144043\n",
      "Epoch: 17/40 Iteration: 7100 Loss: 3.725175619125366\n",
      "Epoch: 17/40 Iteration: 7200 Loss: 3.8837451934814453\n",
      "Epoch: 17/40 Iteration: 7300 Loss: 3.727468729019165\n",
      "Epoch: 18/40 Iteration: 7400 Loss: 4.114819049835205\n",
      "Epoch: 18/40 Iteration: 7500 Loss: 4.269795894622803\n",
      "Epoch: 18/40 Iteration: 7600 Loss: 3.5424964427948\n",
      "Epoch: 18/40 Iteration: 7700 Loss: 4.281130790710449\n",
      "Epoch: 18/40 Iteration: 7800 Loss: 4.306514739990234\n",
      "Epoch: 19/40 Iteration: 7900 Loss: 3.739612579345703\n",
      "Epoch: 19/40 Iteration: 8000 Loss: 4.086330413818359\n",
      "Epoch: 19/40 Iteration: 8100 Loss: 3.703045606613159\n",
      "Epoch: 19/40 Iteration: 8200 Loss: 3.871259927749634\n",
      "Epoch: 20/40 Iteration: 8300 Loss: 3.932020425796509\n",
      "Epoch: 20/40 Iteration: 8400 Loss: 4.262319564819336\n",
      "Epoch: 20/40 Iteration: 8500 Loss: 4.395000457763672\n",
      "Epoch: 20/40 Iteration: 8600 Loss: 3.5832669734954834\n",
      "Epoch: 20/40 Iteration: 8700 Loss: 3.6123046875\n",
      "Epoch: 21/40 Iteration: 8800 Loss: 4.631540298461914\n",
      "Epoch: 21/40 Iteration: 8900 Loss: 3.4502921104431152\n",
      "Epoch: 21/40 Iteration: 9000 Loss: 4.330240726470947\n",
      "Epoch: 21/40 Iteration: 9100 Loss: 3.7872579097747803\n",
      "Epoch: 22/40 Iteration: 9200 Loss: 3.4728989601135254\n",
      "Epoch: 22/40 Iteration: 9300 Loss: 3.992777109146118\n",
      "Epoch: 22/40 Iteration: 9400 Loss: 4.253530025482178\n",
      "Epoch: 22/40 Iteration: 9500 Loss: 3.0203986167907715\n",
      "Epoch: 23/40 Iteration: 9600 Loss: 2.982388496398926\n",
      "Epoch: 23/40 Iteration: 9700 Loss: 3.3457067012786865\n",
      "Epoch: 23/40 Iteration: 9800 Loss: 3.329660415649414\n",
      "Epoch: 23/40 Iteration: 9900 Loss: 3.818049430847168\n",
      "Epoch: 23/40 Iteration: 10000 Loss: 2.8789448738098145\n",
      "Epoch: 24/40 Iteration: 10100 Loss: 3.4215075969696045\n",
      "Epoch: 24/40 Iteration: 10200 Loss: 3.4036741256713867\n",
      "Epoch: 24/40 Iteration: 10300 Loss: 4.0551862716674805\n",
      "Epoch: 24/40 Iteration: 10400 Loss: 3.944000482559204\n",
      "Epoch: 25/40 Iteration: 10500 Loss: 3.2716660499572754\n",
      "Epoch: 25/40 Iteration: 10600 Loss: 3.61156964302063\n",
      "Epoch: 25/40 Iteration: 10700 Loss: 3.630708932876587\n",
      "Epoch: 25/40 Iteration: 10800 Loss: 3.9920692443847656\n",
      "Epoch: 26/40 Iteration: 10900 Loss: 3.7616565227508545\n",
      "Epoch: 26/40 Iteration: 11000 Loss: 3.9964120388031006\n",
      "Epoch: 26/40 Iteration: 11100 Loss: 3.212311029434204\n",
      "Epoch: 26/40 Iteration: 11200 Loss: 3.4425547122955322\n",
      "Epoch: 26/40 Iteration: 11300 Loss: 1.8602728843688965\n",
      "Epoch: 27/40 Iteration: 11400 Loss: 3.7914414405822754\n",
      "Epoch: 27/40 Iteration: 11500 Loss: 3.342013120651245\n",
      "Epoch: 27/40 Iteration: 11600 Loss: 3.1479411125183105\n",
      "Epoch: 27/40 Iteration: 11700 Loss: 3.580000400543213\n",
      "Epoch: 28/40 Iteration: 11800 Loss: 3.3380489349365234\n",
      "Epoch: 28/40 Iteration: 11900 Loss: 2.771169900894165\n",
      "Epoch: 28/40 Iteration: 12000 Loss: 3.7443225383758545\n",
      "Epoch: 28/40 Iteration: 12100 Loss: 3.518001079559326\n",
      "Epoch: 29/40 Iteration: 12200 Loss: 2.6858510971069336\n",
      "Epoch: 29/40 Iteration: 12300 Loss: 3.0532236099243164\n",
      "Epoch: 29/40 Iteration: 12400 Loss: 2.730949640274048\n",
      "Epoch: 29/40 Iteration: 12500 Loss: 2.733785629272461\n",
      "Epoch: 29/40 Iteration: 12600 Loss: 3.1825199127197266\n",
      "Epoch: 30/40 Iteration: 12700 Loss: 3.5291614532470703\n",
      "Epoch: 30/40 Iteration: 12800 Loss: 3.0722031593322754\n",
      "Epoch: 30/40 Iteration: 12900 Loss: 3.0359723567962646\n",
      "Epoch: 30/40 Iteration: 13000 Loss: 2.5041210651397705\n",
      "Epoch: 31/40 Iteration: 13100 Loss: 3.340139627456665\n",
      "Epoch: 31/40 Iteration: 13200 Loss: 2.7962279319763184\n",
      "Epoch: 31/40 Iteration: 13300 Loss: 3.7296383380889893\n",
      "Epoch: 31/40 Iteration: 13400 Loss: 3.1929588317871094\n",
      "Epoch: 32/40 Iteration: 13500 Loss: 2.81620717048645\n",
      "Epoch: 32/40 Iteration: 13600 Loss: 3.2542083263397217\n",
      "Epoch: 32/40 Iteration: 13700 Loss: 3.0958895683288574\n",
      "Epoch: 32/40 Iteration: 13800 Loss: 2.8346328735351562\n",
      "Epoch: 32/40 Iteration: 13900 Loss: 3.527676582336426\n",
      "Epoch: 33/40 Iteration: 14000 Loss: 2.9351701736450195\n",
      "Epoch: 33/40 Iteration: 14100 Loss: 3.382065773010254\n",
      "Epoch: 33/40 Iteration: 14200 Loss: 3.226299285888672\n",
      "Epoch: 33/40 Iteration: 14300 Loss: 3.0781500339508057\n",
      "Epoch: 34/40 Iteration: 14400 Loss: 2.7733242511749268\n",
      "Epoch: 34/40 Iteration: 14500 Loss: 2.521169662475586\n",
      "Epoch: 34/40 Iteration: 14600 Loss: 2.984863758087158\n",
      "Epoch: 34/40 Iteration: 14700 Loss: 3.0920848846435547\n",
      "Epoch: 35/40 Iteration: 14800 Loss: 2.822852611541748\n",
      "Epoch: 35/40 Iteration: 14900 Loss: 3.5166680812835693\n",
      "Epoch: 35/40 Iteration: 15000 Loss: 3.0641672611236572\n",
      "Epoch: 35/40 Iteration: 15100 Loss: 2.61478853225708\n",
      "Epoch: 35/40 Iteration: 15200 Loss: 2.8897643089294434\n",
      "Epoch: 36/40 Iteration: 15300 Loss: 2.8296456336975098\n",
      "Epoch: 36/40 Iteration: 15400 Loss: 2.374727487564087\n",
      "Epoch: 36/40 Iteration: 15500 Loss: 3.6417226791381836\n",
      "Epoch: 36/40 Iteration: 15600 Loss: 3.0632832050323486\n",
      "Epoch: 37/40 Iteration: 15700 Loss: 2.8595290184020996\n",
      "Epoch: 37/40 Iteration: 15800 Loss: 2.6978137493133545\n",
      "Epoch: 37/40 Iteration: 15900 Loss: 2.8376662731170654\n",
      "Epoch: 37/40 Iteration: 16000 Loss: 2.59959077835083\n",
      "Epoch: 38/40 Iteration: 16100 Loss: 3.2521610260009766\n",
      "Epoch: 38/40 Iteration: 16200 Loss: 3.137972831726074\n",
      "Epoch: 38/40 Iteration: 16300 Loss: 2.6043858528137207\n",
      "Epoch: 38/40 Iteration: 16400 Loss: 3.2504026889801025\n",
      "Epoch: 38/40 Iteration: 16500 Loss: 3.232640504837036\n",
      "Epoch: 39/40 Iteration: 16600 Loss: 2.642176389694214\n",
      "Epoch: 39/40 Iteration: 16700 Loss: 3.0476415157318115\n",
      "Epoch: 39/40 Iteration: 16800 Loss: 2.7622575759887695\n",
      "Epoch: 39/40 Iteration: 16900 Loss: 3.0590012073516846\n",
      "Epoch: 40/40 Iteration: 17000 Loss: 3.094912052154541\n",
      "Epoch: 40/40 Iteration: 17100 Loss: 3.0692405700683594\n",
      "Epoch: 40/40 Iteration: 17200 Loss: 3.6502015590667725\n",
      "Epoch: 40/40 Iteration: 17300 Loss: 2.8017349243164062\n",
      "Epoch: 40/40 Iteration: 17400 Loss: 2.6608543395996094\n",
      "Time:1121.2625875473022s\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    net, losses = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size 48469\n",
      "Use LSTM model to predict\n",
      "1 [MASK] = ['咀嚼', 'logo', '吐槽', '马自达', 'Davis'] - 座椅\n",
      "2 [MASK] = ['到来', '<EOS>', '更', '新', '诞生'] - 汽车\n",
      "3 [MASK] = ['采访', '媒体', '<EOS>', '澎湃', 'CNN'] - 欧洲\n",
      "4 [MASK] = ['工艺', '视角', '风格', '设计', '徕'] - 玻璃\n",
      "5 [MASK] = ['华为', '<EOS>', '做生意', '苹果', '一家'] - 利润\n",
      "6 [MASK] = ['屏幕', '<EOS>', '贫穷', '买', '绑定'] - 故宫\n",
      "7 [MASK] = ['客户', '生产', '减员', '<EOS>', '准入'] - 颁发\n",
      "8√ [MASK] = ['<EOS>', '广阔', '看好', '企业', '关注'] - 广阔\n",
      "9 [MASK] = ['<EOS>', '力量', '合作', '探索', '各个环节'] - 对话\n",
      "10√ [MASK] = ['时间', '手机', '系列', '量产', '新'] - 手机\n",
      "11 [MASK] = ['<EOS>', '信息', '数量', '相关', '升级'] - 神经网络\n",
      "12 [MASK] = ['新', '工具', '用户', '未来', '带来'] - 机器人\n",
      "13 [MASK] = ['攻城略地', '饱和', '份额', '更', '机会'] - 应用\n",
      "14√ [MASK] = ['增长', '下滑', '收入', '约', '盈利'] - 增长\n",
      "15 [MASK] = ['<EOS>', '测试', '最终', '特斯拉', '更'] - 学习\n",
      "16 [MASK] = ['业余', '5G', '体系', '商用', '技术'] - 门店\n",
      "17 [MASK] = ['<EOS>', 'APP', '动力系统', '旅游', '10'] - 干燥\n",
      "18 [MASK] = ['人士', '管理条例', '反对', '原厂', '10'] - 政府\n",
      "19√ [MASK] = ['<EOS>', '5G', '厂商', '营业厅', '行业'] - 厂商\n",
      "20 [MASK] = ['合同', '<EOS>', '同比', '号', '计算'] - 裁员\n",
      "21 [MASK] = ['优惠', '元', '单芯片', '万', '度'] - 需求\n",
      "22 [MASK] = ['5G', '将会弃', '月', 'Max', '手机'] - 他们\n",
      "23 [MASK] = ['<EOS>', '毕业生', '信息量', '状态', '孩子'] - 鲜艳\n",
      "24 [MASK] = ['<EOS>', '更', '处分', '信用', '维护'] - 打击\n",
      "25 [MASK] = ['侵犯', '非法', '违反', '公司', '涉嫌'] - 传销\n",
      "26 [MASK] = ['信息', '加密', '<EOS>', '数据', '前'] - 招聘\n",
      "27 [MASK] = ['新闻', '<EOS>', '探索', '群体', '素质'] - 中心\n",
      "28 [MASK] = ['灵长类', '指出', '时说', '简单', '5G'] - 人类\n",
      "29 [MASK] = ['<EOS>', '轨道', '实施', '公司', '2019'] - 程序\n",
      "30 [MASK] = ['黑马', '一种', '校内', '兼容', '货运'] - 班主任\n",
      "31√ [MASK] = ['<EOS>', '位置', '换取', '制胜', '浪费'] - 浪费\n",
      "32 [MASK] = ['2020', '推出', '<EOS>', '5G', '初衷'] - 建设\n",
      "33√ [MASK] = ['提升', '发展', '<EOS>', '强化', '更'] - 发展\n",
      "34 [MASK] = ['发展', '价值', '安居乐业', '一种', '创造'] - 信息技术\n",
      "35√ [MASK] = ['阶段', '未来', '微内核', '沉淀', '医'] - 阶段\n",
      "36 [MASK] = ['同意', '占', '买', '体验', '下载'] - 公安局\n",
      "37√ [MASK] = ['诽谤', '贡献', '回应', '承诺', '家人'] - 诽谤\n",
      "38 [MASK] = ['太空', '加州', '议员', '创新', '德国'] - 商务部\n",
      "39 [MASK] = ['<EOS>', '提供', '解决', '卖', '瞄准'] - 关注\n",
      "40√ [MASK] = ['服务', '用户', '业务', '客户', '包括'] - 服务\n",
      "41 [MASK] = ['量子', '月球', '人类', '火星', '研究'] - 成本\n",
      "42√ [MASK] = ['通信', '账号', '泄露', '服务', '违反'] - 泄露\n",
      "43 [MASK] = ['<EOS>', '中国', '原', '任正非', '美国'] - 运营商\n",
      "44 [MASK] = ['工具', '技术', '一种', '研究', '公司'] - 拖地\n",
      "45 [MASK] = ['中', '员工', '需', '<EOS>', '计划'] - 观众\n",
      "46 [MASK] = ['事件', 'Global', '市', '东海', '一点'] - 基础\n",
      "47 [MASK] = ['<EOS>', '发布', '反馈', '中', '发送'] - 成员\n",
      "48 [MASK] = ['服务', '服务行业', '<EOS>', '方式', '即时'] - 改善\n",
      "49 [MASK] = ['学习', '优秀', '强大', '资金', '企业'] - 资本\n",
      "50√ [MASK] = ['白酒', '均', '费用', '流量', '频率'] - 白酒\n",
      "51 [MASK] = ['建设', '<EOS>', '运维', '生产', '诈骗'] - 安全\n",
      "52 [MASK] = ['<EOS>', '提升', '大会', '升级', '更'] - 零售业\n",
      "53 [MASK] = ['启动', '发布', '开幕', '推出', '上线'] - 宣布\n",
      "54 [MASK] = ['<EOS>', '增长', '市场', '用户', '第一'] - 价格\n",
      "55√ [MASK] = ['停滞', '携带', '用户', '提供', '危机'] - 用户\n",
      "56 [MASK] = ['设备', '手机', '零部件', 'Mac', 'Mate'] - 电池\n",
      "57 [MASK] = ['<EOS>', 'iPhone', '软件', '产品', '版本'] - 屏幕\n",
      "58√ [MASK] = ['汽车', '汽车行业', '指标', '汽车产业', '车是'] - 汽车\n",
      "59 [MASK] = ['创新', '媒体', '巨头', '发展', '公司'] - 企业\n",
      "60 [MASK] = ['20%', '达', '40%', '下车', '电量'] - 时间\n",
      "61 [MASK] = ['2.422', '罚款', 'C', '<EOS>', '上年'] - 价格\n",
      "62 [MASK] = ['500', '农地', '超低', '超过', '超'] - 面积\n",
      "63 [MASK] = ['<EOS>', '6.23', '1.3', '10%', '增加'] - 占比\n",
      "64 [MASK] = ['5G', '<EOS>', '产业', '全球化', '全球'] - 政策\n",
      "65 [MASK] = ['制定者', '红利', '支持', '来源', '想象'] - 法律\n",
      "66 [MASK] = ['30', '日', '19', '美国', '27'] - 销量\n",
      "67 [MASK] = ['实事求是', '受', '<EOS>', '权利义务', '保证'] - 法律\n",
      "68 [MASK] = ['<EOS>', '航天', '建设', '合作', '参与'] - 远\n",
      "69 [MASK] = ['标尺', '提升', '支持', '<EOS>', '优惠'] - 原因\n",
      "70√ [MASK] = ['发布', '京', '7T', '7Pro', '正式'] - 发布\n",
      "71 [MASK] = ['<EOS>', '朝向', '组成部分', '雨', '领带'] - 版本\n",
      "72 [MASK] = ['<EOS>', '剧烈', '市场', '价值', '看作'] - 因素\n",
      "73√ [MASK] = ['<EOS>', '影响', '市场', '客户', '用户'] - 影响\n",
      "74√ [MASK] = ['采访', '网易', '澎湃', '<EOS>', '媒体'] - 媒体\n",
      "75√ [MASK] = ['产品', '应用程序', '技术', '用户', '功能'] - 功能\n",
      "76 [MASK] = ['人士', '提供', '推出', '中', '数据'] - 消费者\n",
      "77√ [MASK] = ['跟踪', '<EOS>', '客户', '留存', '效率'] - 效率\n",
      "78 [MASK] = ['2017', '5G', '<EOS>', '年', '年度'] - 降\n",
      "79 [MASK] = ['<EOS>', '店', '不好', '用户', '区'] - 产品\n",
      "80 [MASK] = ['<EOS>', '认可度', '拓展', '增长', 'EQC'] - 人工智能\n",
      "81 [MASK] = ['部署', '体验', '容量', '互联网', '建设'] - 需求\n",
      "82√ [MASK] = ['套餐', '降速', '阈值', '限速', '推出'] - 套餐\n",
      "83√ [MASK] = ['营收', '总营收', '第三季度', '收入', '国内'] - 营收\n",
      "84 [MASK] = ['系统', '<EOS>', '车间', '电池', '设备'] - 环境\n",
      "85 [MASK] = ['量子', '特别', '第一步', '传统', '显得'] - 资金\n",
      "86 [MASK] = ['网络空间', '电影', '运维', '黑灰产', '翻译'] - 安全\n",
      "87√ [MASK] = ['管家', '代', '服务', '消费者', '<EOS>'] - 服务\n",
      "88 [MASK] = ['<EOS>', '华为', '中国', '美国', '新'] - 亏损\n",
      "89 [MASK] = ['德国', '欧洲', '媒体', '经济', '世界'] - 国家\n",
      "90 [MASK] = ['<EOS>', '公司', '投资', '中', 'We'] - 损失\n",
      "91 [MASK] = ['<EOS>', '落地', '人类', '构建', '更'] - 合作\n",
      "92 [MASK] = ['<EOS>', '倡议书', '挑战', '机会', '阶段'] - 速度\n",
      "93 [MASK] = ['发展', '技术', '场景', '互联网', '领域'] - 人工智能\n",
      "94 [MASK] = ['技术', '机会', '模式', '产业', '趋势'] - 智能机\n",
      "95√ [MASK] = ['产品', '<EOS>', '德国', '尺寸', '充电'] - 产品\n",
      "96 [MASK] = ['<EOS>', '5G', '激进', 'VR', '技术'] - 无线电\n",
      "97 [MASK] = ['收购', '<EOS>', '提出', '公司', '信贷'] - 营收\n",
      "98 [MASK] = ['<EOS>', '互联网', '网络', '用户', '技术'] - 安全\n",
      "99√ [MASK] = ['<EOS>', '价格', 'GB', '更', '以内'] - 价格\n",
      "100√ [MASK] = ['企业', '行业', '公司', '服务', '时'] - 企业\n",
      "Accuracy: 24.00%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The following part is used for prediction and generating the answers\n",
    "\"\"\"\n",
    "\n",
    "import jieba\n",
    "\n",
    "stopwords = [word[:-1] for word in open(\"stopwords.txt\",\"r\",encoding=\"utf-8\")] # delete \\n\n",
    "\n",
    "def generate_seg_lst(lst):\n",
    "    cut_lst = jieba.lcut(lst,cut_all=False)\n",
    "    res = []\n",
    "    for word in cut_lst:\n",
    "        if word not in stopwords and word != \"\\n\":\n",
    "            res.append(word)\n",
    "    return res\n",
    "\n",
    "def predict(device, net, question_str, n_word, word_to_int, int_to_word, top_k=5):\n",
    "    \"\"\"\n",
    "    Use `net` to do the prediction\n",
    "    Each time only one `question_str` is input\n",
    "    \"\"\"\n",
    "    net.eval() # set in evaluation mode\n",
    "    # find out the blank\n",
    "    q_index = question_str.index(\"[MASK]\")\n",
    "    question_pre, question_post = question_str[:q_index], question_str[q_index+len(\"[MASK]\"):]\n",
    "\n",
    "    # cut the sentence\n",
    "    seg_pre = generate_seg_lst(question_pre)\n",
    "    seg_post = generate_seg_lst(question_post)\n",
    "    seg_pre.insert(0,\"<BOS>\")\n",
    "    seg_post.insert(len(seg_post),\"<EOS>\")\n",
    "\n",
    "    # LSTM inference\n",
    "    state_h, state_c = net.zero_state(1)\n",
    "    state_h = state_h.to(device)\n",
    "    state_c = state_c.to(device)\n",
    "    for w in seg_pre:\n",
    "        index = word_to_int.get(w,word_to_int[\"<BOS>\"])\n",
    "        ix = torch.tensor([[index]]).to(device)\n",
    "        output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
    "\n",
    "    # get the topk prediction\n",
    "    _, top_ix = torch.topk(output[0], k=top_k)\n",
    "    choices = top_ix.tolist()\n",
    "\n",
    "    # return the corresponding words\n",
    "    return [int_to_word[x] for x in choices[0]]\n",
    "\n",
    "top_k = 5 # flags.top_k\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_set = TextDataset(flags.train_file_path, flags.batch_size, flags.seq_size)\n",
    "\n",
    "# load from previous models\n",
    "net = RNNModule(train_set.n_word, flags.seq_size,flags.embedding_size, flags.lstm_size)\n",
    "net.load_state_dict(torch.load(\"checkpoint/model-10000.pth\"))\n",
    "net.to(device)\n",
    "\n",
    "groundtrue = [line[:-1] for line in open(\"answer.txt\",\"r\",encoding=\"utf-8\")]\n",
    "acc = 0\n",
    "\n",
    "myanswer = open(\"myanswer-lstm-{}.txt\".format(top_k),\"w\",encoding=\"utf-8\")\n",
    "\n",
    "print(\"Use LSTM model to predict\")\n",
    "with open(\"questions.txt\",\"r\",encoding=\"utf-8\") as question_file:\n",
    "    for i,question_str in enumerate(question_file,1):\n",
    "        pred = predict(device, net, question_str, train_set.n_word, train_set.word_to_int, train_set.int_to_word, top_k)\n",
    "        if groundtrue[i-1] in pred:\n",
    "            acc += 1\n",
    "            print(\"{}√ [MASK] = {} - {}\".format(i,pred,groundtrue[i-1]),flush=True)\n",
    "        else:\n",
    "            print(\"{} [MASK] = {} - {}\".format(i,pred,groundtrue[i-1]),flush=True)\n",
    "        myanswer.write(\"{}\\n\".format(\" \".join(pred)))\n",
    "\n",
    "print(\"Accuracy: {:.2f}%\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.savefig(r\"train_loss.pdf\",format=\"pdf\",dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
