{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.2"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "attr_dict = {\"age\":0, \"workclass\":1, \"fnlwgt\":0, \"education\":1, \"education-num\":0, \"marital-status\":1, \"occupation\":1, \"relationship\":1, \"race\":1, \"sex\":1, \"capital-gain\":0, \"capital-loss\":0, \"hours-per-week\":0, \"native-country\":1, \"salary\":0} # 0: continuous, 1: discrete\n",
    "\n",
    "train_data = pd.read_csv(\"adult.data\",names=attr_dict.keys(),index_col=False)\n",
    "test_data = pd.read_csv(\"adult.test\",names=attr_dict.keys(),index_col=False,header=0)\n",
    "\n",
    "def preprocessing(data):\n",
    "    \"\"\"\n",
    "    Select some useful attributes\n",
    "    \"\"\"\n",
    "    # attributes = [\"workclass\",\"education\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"native-country\",\"salary\"] # discrete\n",
    "    attributes = list(attr_dict.keys())\n",
    "    attributes.remove(\"fnlwgt\")\n",
    "    attributes.remove(\"capital-gain\")\n",
    "    attributes.remove(\"capital-loss\")\n",
    "    return data[attributes]\n",
    "\n",
    "def fill_data(data,flag=1):\n",
    "    \"\"\"\n",
    "    Fill in missing data (?)\n",
    "    \"\"\"\n",
    "    if flag == 0: # directly remove missing data\n",
    "        for a in data.columns.values:\n",
    "            if attr_dict[a]: # discrete\n",
    "                data = data[data[a] != \" ?\"] # remove unknown\n",
    "        return data\n",
    "    else: # fill data with the most value\n",
    "        for a in data.columns.values:\n",
    "            if attr_dict[a]: # discrete\n",
    "                data.loc[data[a] == \" ?\",a] = data[a].value_counts().argmax() # view or copy? Use loc!\n",
    "            else: # continuous\n",
    "                pass\n",
    "        return data\n",
    "\n",
    "# Data cleaning\n",
    "train_data = preprocessing(train_data)\n",
    "test_data = preprocessing(test_data)\n",
    "train_data = fill_data(train_data,1)\n",
    "test_data = fill_data(test_data,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier():\n",
    "    \"\"\"\n",
    "    A Naive Bayes Classifier\n",
    "    \"\"\"\n",
    "    def __init__(self,train_data,attr_dict):\n",
    "        \"\"\"\n",
    "        Initialize and calculate the aprior probability\n",
    "        \"\"\"\n",
    "        self.train_data = train_data\n",
    "        self.attr_dict = attr_dict\n",
    "\n",
    "        # calculate the aprior probability P(x_i|y)\n",
    "        self.prob = {}\n",
    "        self.prob[\" >50K\"] = train_data[\"salary\"].value_counts(normalize=True)[\" >50K\"]\n",
    "        self.prob[\" <=50K\"] = 1 - self.prob[\" >50K\"]\n",
    "        self.attributes = train_data.columns.values[train_data.columns.values != \"salary\"]\n",
    "        less_than_50k = train_data[train_data[\"salary\"] == \" <=50K\"]\n",
    "        greater_than_50k = train_data[train_data[\"salary\"] == \" >50K\"]\n",
    "        for a in self.attributes:\n",
    "            if self.attr_dict[a]: # discrete\n",
    "                count_a_less_than_50k = less_than_50k[a].value_counts()\n",
    "                count_a_greater_than_50k = greater_than_50k[a].value_counts()\n",
    "                V = len(train_data[a].unique())\n",
    "                for xi in train_data[a].unique():\n",
    "                    # laplacian smoothing\n",
    "                    self.prob[(xi,\" <=50K\")] = (count_a_less_than_50k.get(xi,0) + 1) / (len(less_than_50k) + V)\n",
    "                    self.prob[(xi,\" >50K\")] = (count_a_greater_than_50k.get(xi,0) + 1) / (len(greater_than_50k) + V)\n",
    "            else: # continuous\n",
    "                # use Gaussian aprior\n",
    "                mu_less_than_50k = np.mean(less_than_50k[a])\n",
    "                sigma_less_than_50k = np.var(less_than_50k[a])\n",
    "                self.prob[(a,\" <=50K\")] = lambda x: 1 / np.sqrt(2*np.pi*sigma_less_than_50k) * np.exp(-(x-mu_less_than_50k)**2/(2*sigma_less_than_50k)) # use anonymous function\n",
    "                mu_greater_than_50k = np.mean(greater_than_50k[a])\n",
    "                sigma_greater_than_50k = np.var(greater_than_50k[a])\n",
    "                self.prob[(a,\" >50K\")] = lambda x: 1 / np.sqrt(2*np.pi*sigma_greater_than_50k) * np.exp(-(x-mu_greater_than_50k)**2/(2*sigma_greater_than_50k))\n",
    "\n",
    "    def predict(self,test_data):\n",
    "        \"\"\"\n",
    "        Predict the salary of test data\n",
    "        \"\"\"\n",
    "        acc = 0\n",
    "        for i, row in test_data.iterrows():\n",
    "            # calculate P(y|x_1,...,x_n)\n",
    "            prod = np.array([self.prob[\" <=50K\"],self.prob[\" >50K\"]])\n",
    "            for a in self.attributes:\n",
    "                xi = row[a]\n",
    "                if self.attr_dict[a]: # discrete\n",
    "                    prod[0] *= self.prob[(xi,\" <=50K\")]\n",
    "                    prod[1] *= self.prob[(xi,\" >50K\")]\n",
    "                else: # continuous\n",
    "                    prod[0] *= self.prob[(a,\" <=50K\")](xi)\n",
    "                    prod[1] *= self.prob[(a,\" >50K\")](xi)\n",
    "\n",
    "            # find the catagory with the max probability\n",
    "            catagory = \" <=50K\" if prod.argmax() == 0 else \" >50K\"\n",
    "            if catagory == row[\"salary\"][:-1]: # be careful of \".\"\n",
    "                acc += 1\n",
    "            if i % 1000 == 0:\n",
    "                print(\"Finish {}/{}\".format(i,len(test_data)))\n",
    "\n",
    "        acc /= len(test_data)\n",
    "        print(\"Accurary: {:.2f}%\".format(acc * 100))\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Finish 0/16281\nFinish 1000/16281\nFinish 2000/16281\nFinish 3000/16281\nFinish 4000/16281\nFinish 5000/16281\nFinish 6000/16281\nFinish 7000/16281\nFinish 8000/16281\nFinish 9000/16281\nFinish 10000/16281\nFinish 11000/16281\nFinish 12000/16281\nFinish 13000/16281\nFinish 14000/16281\nFinish 15000/16281\nFinish 16000/16281\nAccurary: 82.18%\n"
    },
    {
     "data": {
      "text/plain": "0.8217554204287206"
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = NaiveBayesClassifier(train_data,attr_dict)\n",
    "nb.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}