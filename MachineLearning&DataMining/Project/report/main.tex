\documentclass[logo,reportComp]{thesis}
\usepackage[python,pseudo]{mypackage}

\title{机器学习与数据挖掘大作业}
\subtitle{多标签用户人格分类（集成学习）}
\school{数据科学与计算机学院}
\author{陈鸿峥}
\classname{17大数据与人工智能}
\stunum{17341015}
\headercontext{机器学习与数据挖掘大作业}

\let\emph\relax % there's no \RedeclareTextFontCommand
\DeclareTextFontCommand{\emph}{\kaiti\em}

\begin{document}

\maketitle
\tableofcontents

\newpage
MBTI理论认为一个人的个性可以从四个角度进行分析，用字母代表如下：
\begin{itemize}
    \item 驱动力的来源：外向E---内向I
    \item 接受信息的方式：感觉S---直觉N
    \item 决策的方式：思维T---情感F
    \item 对待不确定性的态度：判断J---知觉P
\end{itemize}
按照不同的组合，可以产生16种人格类型。

本次大作业要求利用机器学习方法，通过用户的发言记录对用户的人格类型进行分类\footnote{数据集链接：\url{https://www.kaggle.com/datasnaek/mbti-type}}。

本实验报告为大作业的第一部分---\textbf{集成学习}方法。

\section{预处理}
由于原始数据集为用户在网页上的发言记录，非常随意及杂乱，故做分类任务前的第一步需要灵活应用上学期自然语言处理学过的知识，对数据集进行预处理操作。
主要分为以下几个步骤。

\subsection{文本清洗}
\begin{itemize}
	\item 标点后强制添加空格。
	由于是网页发言记录，很多用户可能不会太过在意标点符号后面是否有空格。如果没有添加，则之后删除标点可能会导致前后两个词语粘连。
	\item 移除网页链接。
	由于网页地址通常没有太多含义，故这里直接将发言记录中出现的网页链接直接移除。
	采用以下的正则表达式对http/https开头的网址进行匹配。
\begin{lstlisting}
(http|https):\/\/.*?( |'|\")
\end{lstlisting}
	\item 移除数字。
	同理，数字带来的信息非常少，无法作为区分人格的合理因素，故也将其移除。
	\item 移除标点符号。
	我们做文本分类时，关心的是用户说过的词语，而不是他是否有进行断句，故也将所有标点符号移除。
	这里采用了一种比较高效的方法，直接调用C库对字符串进行处理。
\begin{lstlisting}
new_post = new_post.translate(str.maketrans('', '', string.punctuation))
\end{lstlisting}
	注意两条评论之间采用\verb'|||'进行分隔，但我们直接将其移除了，意味着我们并不关心用户发言记录的先后顺序，我们更关心的其说过什么话。
	\item 移除空格。
	句子内部空格用正则表达式匹配\verb' +'后用单一空格代替；句子前后的空格用Python内置的\verb'strip'函数即可移除。
	\item 字母小写化。
	避免计算机认为不同大小写字母构成的为不同的词语，如"Hello"和"hello"两者意思相同，代表的是同一个词，故要进行规范化。
	\item 移除停止词(stopping words)。
	这是很多NLP任务中必备的一步，因为停止词并不会带来任何更多语义上的信息。
	这里采用上学期NLP大作业提供的停止词列表\cite{bib:stopping_words}。
\end{itemize}

这里做的操作都比较常规，并没有对该数据集进行特定优化，如果后续作业中想继续对预处理部分进行改进，可以考虑以下几个方面：
\begin{itemize}
	\item 表情符号的处理。
	从这些用户的发言记录中可以发现，外国网友也是很喜欢用emoji甚至颜文字的。
	emoji比较好辨别，均用两个冒号括起来，如\verb':sad:'。
	颜文字如\verb':)'和\verb':('，这是用得比较多的，但被我们在前面的预处理中移除了。
	而喜欢用这些表情符号的可能恰恰对应着某一类人，因此可以单独对其进行处理，做成单独的特征，供后续的机器学习模型使用。
	\item 词型变位。
	目前还没有做这方面的处理，可能需要结合nltk包将不同的词性但代表同一个词语的单词进行合并。
	这可能会对后续词频及词向量的生成造成一定影响。
\end{itemize}

\section{集成模型}
\subsection{数据生成}
\subsection{模型搭建}
\subsection{模型训练}
\subsection{模型预测}
\subsection{其他实现细节}
中间结果文件保存

\section{实验结果}
只使用了基本了numpy和pandas库用于做矩阵运算及数据处理。

\subsection{超参数选择}
\subsection{综合比较}
\section{总结与思考}
充分利用上学期自然语言处理课程的知识。

\begin{thebibliography}{99}
\bibitem{bib:stopping_words}
\end{thebibliography}

\end{document}

% 作业内容：
% 1. 使用集成学习方法完成人格分类（6月10日）
% * 对数据进行预处理
% * 使用集成学习模型(AdaBoost或Random Forest)进行人格分类
% * 提交报告及代码
% 2. 使用SVM进行人格分类（6月30日）
% * 数据预处理
% * 使用SVM进行人格分类
% * 提交报告及代码
% 3. 使用深度学习模型进行人格分类（7月31日）
% * 数据预处理
% * 使用深度学习模型（不限）进行人格分类
% * 提交代码和报告
% ** 深度学习方法需要有方法上的创新，如果只简单使用开源代码或框架，最多只能拿8分
% ** 加分项：使用英文撰写报告，设计合理实验（对比不同模型表现/不同超参数对性能的影响），自己撰写模型代码，尽可能少调用工具

% 评价指标：
% * 单独对每种类别进行评价/整体评价
% * F1 \& Accuracy

% 评分：
% * 集成学习方法：8分
% * SVM方法：8分
% * 深度学习方法：14分